{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, SimpleRNN, Dropout, RepeatVector\n",
    "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping\n",
    "\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(52)\n",
    "all_char = '0123456789+'\n",
    "\n",
    "num_feature = len(all_char)\n",
    "\n",
    "char_to_idx = dict((c,i) for i,c in enumerate(all_char))\n",
    "idx_to_char = dict((i,c) for i,c in enumerate(all_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('28+11', '39')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_data():\n",
    "    first = np.random.randint(0,100)\n",
    "    second = np.random.randint(0,100)\n",
    "    data = str(first)+'+'+str(second)\n",
    "    label = str(first+second)\n",
    "    return data,label\n",
    "generate_data()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating  the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 128)               17920     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 5, 128)            32896     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 5, 11)             1419      \n",
      "=================================================================\n",
      "Total params: 52,235\n",
      "Trainable params: 52,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_units = 128\n",
    "max_time_steps = 5\n",
    "\n",
    "model = Sequential([\n",
    "    SimpleRNN(hidden_units, input_shape = (None, num_feature)),\n",
    "    RepeatVector(max_time_steps),\n",
    "    SimpleRNN(hidden_units, return_sequences = True),\n",
    "    TimeDistributed(Dense(num_feature, activation = 'softmax'))\n",
    "])\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['acc']\n",
    "\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13+23 = 36\n"
     ]
    }
   ],
   "source": [
    "def vectorize_example(example, label):\n",
    "    x = np.zeros((max_time_steps, num_feature))\n",
    "    y = np.zeros((max_time_steps, num_feature))\n",
    "    \n",
    "    diff_x = max_time_steps - len(example)\n",
    "    diff_y = max_time_steps - len(label)\n",
    "    \n",
    "    for i,c in enumerate(example):\n",
    "        x[i+diff_x,char_to_idx[c]] = 1\n",
    "    for i in range(diff_x):\n",
    "        x[i, char_to_idx['0']] = 1\n",
    "    \n",
    "    for i,c in enumerate(label):\n",
    "        y[i+diff_y,char_to_idx[c]] = 1\n",
    "    \n",
    "    for i in range(diff_y):\n",
    "        y[i, char_to_idx['0']] = 1\n",
    "    return x,y\n",
    "\n",
    "e,l = generate_data()\n",
    "e_v, l_v = vectorize_example(e,l)\n",
    "print(e+' = '+l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00036\n"
     ]
    }
   ],
   "source": [
    "def devectorize(example):\n",
    "    res = [idx_to_char[np.argmax(vec)] for vec in example ]\n",
    "    return ''.join(res)\n",
    "\n",
    "print(devectorize(l_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_dataset(num_data):\n",
    "    x = np.zeros((num_data, max_time_steps, num_feature))\n",
    "    y = np.zeros((num_data, max_time_steps, num_feature))\n",
    "    \n",
    "    for i in range(num_data):\n",
    "        e, l =generate_data()\n",
    "        e_v, l_v = vectorize_example(e, l)\n",
    "        x[i] = e_v\n",
    "        y[i] = l_v\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57_0.61_0.62_0.63_0.63_0.64_0.64_0.64_0.64_0.65_0.65_0.65_0.65_0.66_0.66_0.68_0.67_0.67_0.69_0.70_0.70_0.71_0.71_0.72_0.73_0.72_0.72_0.72_0.73_0.73_0.72_0.74_0.74_0.75_0.75_0.75_0.76_0.76_0.76_0.76_0.77_0.76_0.77_0.78_0.78_0.79_0.79_0.79_0.80_0.80_0.80_0.80_0.82_0.82_0.82_0.82_0.83_0.83_0.84_0.84_0.85_0.86_0.85_0.86_0.87_0.88_0.87_0.88_0.88_0.88_0.89_0.89_0.89_0.90_0.90_0.90_0.89_0.90_0.90_0.91_0.90_0.90_0.91_0.91_0.91_0.91_0.91_0.91_0.91_0.91_0.91_0.92_0.92_0.92_0.92_0.92_0.92_0.92_0.93_0.93_0.92_0.92_0.93_0.93_0.93_0.93_0.93_0.94_0.94_0.93_0.93_0.93_0.94_0.94_0.94_0.94_0.94_0.94_0.94_0.94_0.94_0.93_0.94_0.94_0.95_0.94_0.94_0.94_0.95_0.95_0.94_0.95_0.94_0.95_0.94_0.95_0.95_0.95_0.94_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.96_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.96_0.95_0.95_0.95_0.95_0.95_0.95_0.95_0.96_0.96_0.95_0.95_0.95_0.95_0.95_0.96_0.95_0.96_0.96_0.95_0.95_0.95_0.95_"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a1705e37c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = Create_dataset(num_data=2000)\n",
    "l_cb = LambdaCallback(\n",
    "    on_epoch_end= lambda e, l : print('{:0.2f}'.format(l['val_acc']),end='_')\n",
    ")\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.fit(\n",
    "    x,y,epochs=500, batch_size=256, validation_split=0.2,verbose=False,\n",
    "    callbacks=[l_cb,es_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mInput: 77+30 ans = 00107 prediction = 00107\u001b[0m\n",
      "\u001b[32mInput: 60+14 ans = 00074 prediction = 00074\u001b[0m\n",
      "\u001b[32mInput: 61+16 ans = 00077 prediction = 00077\u001b[0m\n",
      "\u001b[32mInput: 58+10 ans = 00068 prediction = 00068\u001b[0m\n",
      "\u001b[32mInput: 24+58 ans = 00082 prediction = 00082\u001b[0m\n",
      "\u001b[32mInput: 60+79 ans = 00139 prediction = 00139\u001b[0m\n",
      "\u001b[31mInput: 04+11 ans = 00015 prediction = 00025\u001b[0m\n",
      "\u001b[32mInput: 77+48 ans = 00125 prediction = 00125\u001b[0m\n",
      "\u001b[32mInput: 92+50 ans = 00142 prediction = 00142\u001b[0m\n",
      "\u001b[32mInput: 59+66 ans = 00125 prediction = 00125\u001b[0m\n",
      "\u001b[32mInput: 50+11 ans = 00061 prediction = 00061\u001b[0m\n",
      "\u001b[32mInput: 88+85 ans = 00173 prediction = 00173\u001b[0m\n",
      "\u001b[32mInput: 49+17 ans = 00066 prediction = 00066\u001b[0m\n",
      "\u001b[32mInput: 63+23 ans = 00086 prediction = 00086\u001b[0m\n",
      "\u001b[32mInput: 20+38 ans = 00058 prediction = 00058\u001b[0m\n",
      "\u001b[31mInput: 004+5 ans = 00009 prediction = 00019\u001b[0m\n",
      "\u001b[32mInput: 22+98 ans = 00120 prediction = 00120\u001b[0m\n",
      "\u001b[32mInput: 04+76 ans = 00080 prediction = 00080\u001b[0m\n",
      "\u001b[32mInput: 02+21 ans = 00023 prediction = 00023\u001b[0m\n",
      "\u001b[32mInput: 63+59 ans = 00122 prediction = 00122\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "x_test,y_test = Create_dataset(num_data=20)\n",
    "\n",
    "preds = model.predict(x_test)\n",
    "\n",
    "for i,pred in enumerate(preds):\n",
    "    ans = devectorize(y_test[i])\n",
    "    prediction = devectorize(pred)\n",
    "    \n",
    "    col = 'green'\n",
    "    \n",
    "    if ans!=prediction:\n",
    "        col = 'red'\n",
    "    out = 'Input: '+devectorize(x_test[i])+' ans = '+ans+' prediction = '+prediction\n",
    "    print(colored(out,col))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
